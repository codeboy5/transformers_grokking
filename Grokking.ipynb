{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Contains code to train the transformer on toy dataset\n",
        "\n",
        "References:\n",
        "1. https://github.com/danielmamay/grokking/blob/main/grokking/training.py"
      ],
      "metadata": {
        "id": "vLz0Ee7MIulf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model import Transformer, Config\n",
        "from gen_data import get_dataset\n",
        "\n",
        "# to ensure that the results are reproducible\n",
        "torch.manual_seed(seed=42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Y6Yos8FMIVHt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Config\n",
        "cfg = Config()\n",
        "\n",
        "train_dataset, valid_dataset = get_dataset(cfg)\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)"
      ],
      "metadata": {
        "id": "1E8IbgwlJFXA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_loader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEdlVy3xhK3p",
        "outputId": "252933a4-4318-4f27-aa2b-cd2be58f4562"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5646"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the training and validation loops"
      ],
      "metadata": {
        "id": "P2aqSoQPLklB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainval_loop(model, optimizer, lr_scheduler, dataloader, is_train=False):\n",
        "\n",
        "  if is_train:\n",
        "    model.train()\n",
        "  else:\n",
        "    model.eval()\n",
        "\n",
        "  # cross entropy loss\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  loss_total = 0\n",
        "  accuracy = 0\n",
        "\n",
        "  for X,y in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    X = X.to(device) # (512, 4)\n",
        "    y = y.to(device) # 512\n",
        "\n",
        "    # validation\n",
        "    if not is_train:\n",
        "      with torch.no_grad():\n",
        "        yhat = model(X)\n",
        "        yhat = yhat[-1]\n",
        "\n",
        "        loss = criterion(yhat, y)\n",
        "\n",
        "        # Calculate the Accuracy\n",
        "        preds = torch.argmax(yhat, dim=1)\n",
        "        acc = (preds == y).sum()\n",
        "\n",
        "        loss_total += loss.item() * len(y)\n",
        "        accuracy += acc.item()\n",
        "\n",
        "    else:\n",
        "      yhat = model(X) # torch.Size([4, 512, 99])\n",
        "      yhat = yhat[-1]\n",
        "\n",
        "      loss = criterion(yhat, y)\n",
        "\n",
        "      # update the model weights\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      lr_scheduler.step()\n",
        "\n",
        "      # Calculate the Accuracy\n",
        "      preds = torch.argmax(yhat, dim=1)\n",
        "      acc = (preds == y).sum()\n",
        "\n",
        "      loss_total += loss.item() * len(y)\n",
        "      accuracy += acc.item()\n",
        "\n",
        "  return loss_total/len(dataloader.dataset), accuracy/len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "jvtM0TLJLtzD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WpIDY-PWIG3d"
      },
      "outputs": [],
      "source": [
        "# Load the model and the optimizers\n",
        "model = Transformer(cfg).to(device)\n",
        "\n",
        "# NOTE: Default setting used in the paper\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1, betas=[0.9, 0.98])\n",
        "\n",
        "# Adam with LR = 3e-4\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "# linear learning rate warm over the first 10 updates\n",
        "lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = math.ceil( cfg.num_updates / len(train_loader) )\n",
        "steps_per_epoch = math.ceil( len(train_loader.dataset)  / 512 )"
      ],
      "metadata": {
        "id": "F7Jlk4AsLOTA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc, val_acc, train_loss, val_loss = [], [], [], []\n",
        "\n",
        "for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "\n",
        "  # Training Loops\n",
        "  loss, acc = trainval_loop(model, optimizer, lr_scheduler, train_loader, is_train = True)\n",
        "  train_loss.append(loss)\n",
        "  train_acc.append(acc)\n",
        "\n",
        "  # Calculating the validation loss\n",
        "  loss, acc = trainval_loop(model, optimizer, lr_scheduler, valid_loader, is_train = False)\n",
        "  val_loss.append(loss)\n",
        "  val_acc.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMXWhirhS7qX",
        "outputId": "5f2b1ffb-11ba-435e-a6f9-05bd0c9f5ac3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12500/12500 [30:29<00:00,  6.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_title = \"Modular Addition (training on {} of data) with {}\".format(str(cfg.split_size*100), \"AdamW With Weight Decay\")\n",
        "\n",
        "steps = torch.arange(len(train_acc)).numpy() * steps_per_epoch\n",
        "plt.plot(steps, train_acc, label=\"train\")\n",
        "plt.plot(steps, val_acc, label=\"val\")\n",
        "plt.legend()\n",
        "plt.title( plot_title )\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xscale(\"log\", base=10)\n",
        "plt.savefig(\"results/acc_{}_adamW_wdecay.png\".format(str(cfg.split_size*100)), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "plt.plot(steps, train_loss, label=\"train\")\n",
        "plt.plot(steps, val_loss, label=\"val\")\n",
        "plt.legend()\n",
        "plt.title( plot_title )\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xscale(\"log\", base=10)\n",
        "plt.savefig(\"results/loss_{}_adamW_wdecay.png\".format(str(cfg.split_size*100)), dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "D40uhwBuatnj"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}